{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# # Add the root folder to the module search path\n",
    "# # Get the current directory\n",
    "# current_directory = os.getcwd()\n",
    "\n",
    "# # Move two levels up (go to the parent directory of the parent directory)\n",
    "# two_levels_up_directory = os.path.dirname(os.path.dirname(current_directory))\n",
    "\n",
    "# print(two_levels_up_directory)\n",
    "\n",
    "# sys.path.append(two_levels_up_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyngrok\n",
    "# !pip install mlflow\n",
    "# !pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/koi/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pykoi.rlhf import RLHFConfig\n",
    "from pykoi.rlhf import SupervisedFinetuning\n",
    "import mlflow\n",
    "import datetime\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train RLHF using the data from database\n",
    "\n",
    "Let's take a look of the QA data and process it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is InstructGPT?</td>\n",
       "      <td>InstructGPT is a language model developed by O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why does InstructGPT work?</td>\n",
       "      <td>InstructGPT works due to a two-step training p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are some commonly used evaluation metrics...</td>\n",
       "      <td>One main evaluation metric for InstructGPT is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How is InstructGPT used?</td>\n",
       "      <td>InstructGPT can be used in any application tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are some common applications of InstructGPT?</td>\n",
       "      <td>Common applications of InstructGPT can be in e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0                               What is InstructGPT?   \n",
       "1                         Why does InstructGPT work?   \n",
       "2  What are some commonly used evaluation metrics...   \n",
       "3                           How is InstructGPT used?   \n",
       "4  What are some common applications of InstructGPT?   \n",
       "\n",
       "                                              Answer  \n",
       "0  InstructGPT is a language model developed by O...  \n",
       "1  InstructGPT works due to a two-step training p...  \n",
       "2  One main evaluation metric for InstructGPT is ...  \n",
       "3  InstructGPT can be used in any application tha...  \n",
       "4  Common applications of InstructGPT can be in e...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_root = \"input/\"\n",
    "input_file = \"rlhf_qa_dataset.json\"\n",
    "stack_exchange_df = pd.read_json(input_root + input_file)\n",
    "stack_exchange_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My ranking database has 45 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Question', 'Answer'],\n",
       "    num_rows: 45\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "print(\"My ranking database has {} samples\".format(stack_exchange_df.shape[0]))\n",
    "dataset = Dataset.from_dict(stack_exchange_df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with RLHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/05 01:22:16 INFO mlflow.tracking.fluent: Experiment with name 'rlhf_step2_reward/2023-10-05 01:22:16.267979' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/ubuntu/pykoi/example/rlhf/mlflow/mlruns/529075251471367022', creation_time=1696468936281, experiment_id='529075251471367022', last_update_time=1696468936281, lifecycle_stage='active', name='rlhf_step2_reward/2023-10-05 01:22:16.267979', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up mlflow experiment name.\n",
    "\n",
    "# mlflow.set_tracking_uri(\"http://x.x.x.x:5000\")\n",
    "experiment = \"rlhf_step2_reward\"\n",
    "current_time = str(datetime.datetime.now())\n",
    "mlflow_experiment_name = '/'.join([experiment, current_time])\n",
    "\n",
    "try:\n",
    "    mlflow.end_run()\n",
    "except:\n",
    "    print(\"No mlflow run in progress\")\n",
    "\n",
    "mlflow.set_experiment(mlflow_experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pykoi parameters.\n",
    "reward_model_path = \"elinas/llama-7b-hf-transformers-4.29\"\n",
    "dataset_type = \"local_db\"\n",
    "trained_model_path = \"./models/rlhf_step2_rw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/rlhf_step2_rw'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually log pykoi parameters into mlflow. Torch level parameters are automatically logged.\n",
    "mlflow.log_param(\"pykoi_reward_model_path\", reward_model_path)\n",
    "mlflow.log_param(\"pykoi_dataset_type\", dataset_type)\n",
    "mlflow.log_param(\"pykoi_trained_model_path\", trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run supervised finetuning\n",
    "# Training metrics are automatically logged into mlflow.\n",
    "config = RLHFConfig(reward_model_path=reward_model_path, \n",
    "                          dataset_type=dataset_type,\n",
    "                          )\n",
    "rlhf_step2_rft = RewardFinetuning(config)\n",
    "rlhf_step2_rft.train_and_save(trained_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained reward model and input into mlflow artifacts.\n",
    "mlflow.log_artifacts(trained_model_path)\n",
    "mlflow.log_artifacts(input_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the terminal, run\n",
    "```\n",
    "mlflow ui\n",
    "```\n",
    "and go to http://127.0.0.1:5000 in the browser to view the experiment in the UI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykoi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
